{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory (optional during development)\n",
    "import os\n",
    "os.chdir('/Users/sudishmakarki/My_project2')  # only if needed\n",
    "print(\" Working directory:\", os.getcwd())\n",
    "\n",
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "\n",
    "# Custom Functions\n",
    "from models.data_interpolation import (\n",
    "    load_data,\n",
    "    preprocess_data,\n",
    "    split_train_test,\n",
    "    generate_time_series_splits\n",
    ")\n",
    "\n",
    "from models.model_prophet import (\n",
    "    prepare_prophet_data,\n",
    "    train_baseline_prophet,\n",
    "    forecast_with_model,\n",
    "    calculate_peak_hours,\n",
    "    evaluate_metrics,\n",
    "    cross_validate_baseline\n",
    ")\n",
    "\n",
    "from models.model_prophet import (\n",
    "    tune_prophet_model,\n",
    "    forecast_with_model_r1,\n",
    "    select_peak_hours,\n",
    "    evaluate_tuned_model_metrics,\n",
    "    cross_validate_tuned_r1,\n",
    "    forecast_future_with_model_r1\n",
    ")\n",
    "\n",
    "from models.model_prophet import (\n",
    "    prepare_holiday_df,\n",
    "    tune_prophet_model_r2,\n",
    "    forecast_with_model_r2,\n",
    "    select_peak_hours_r2,\n",
    "    evaluate_metrics_r2,\n",
    "    cross_validate_model_r2,\n",
    "    forecast_future_with_model_r2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess\n",
    "df = load_data('data/RestaurantData.csv')\n",
    "df_clean = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "restaurant_train, restaurant_test = split_train_test(df_clean, split_date='2022-01-01')\n",
    "# Format for Prophet\n",
    "restaurant_train_prophet, restaurant_test_prophet = prepare_prophet_data(restaurant_train, restaurant_test)\n",
    "# Train the baseline Prophet model\n",
    "m = train_baseline_prophet(restaurant_train_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Test Set Forecasting --\n",
    "# Predict on the test set and display the first few rows\n",
    "test_forecast_df = forecast_with_model(m, restaurant_test_prophet)\n",
    "print(\"Forecast on Test Set (first 5 rows):\")\n",
    "test_forecast_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average forecast per hour\n",
    "hourly_avg = test_forecast_df.groupby('Hour')['yhat'].mean()\n",
    "print(\"\\nAverage Forecast by Hour:\")\n",
    "display(hourly_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_hours_dynamic, hourly_avg, threshold = calculate_peak_hours(test_forecast_df)\n",
    "\n",
    "print(\"\\nThreshold for Peak Hours:\", threshold)\n",
    "print(\"\\nDynamically Identified Peak Hours:\", peak_hours_dynamic)\n",
    "\n",
    "# Filter forecast and actuals for dynamically identified peak hours\n",
    "forecast_peak_df = test_forecast_df[test_forecast_df['Hour'].isin(peak_hours_dynamic)]\n",
    "actual_peak_df = restaurant_test_prophet[restaurant_test_prophet['Hour'].isin(peak_hours_dynamic)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Average forecasted customer count by hour -----\n",
    "plt.figure(figsize=(10, 5))\n",
    "hourly_avg.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Average Forecasted Customer Count by Hour\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Average Forecast (yhat)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Compare Forecast to Actuals (All Hours) -----\n",
    "# Plot the forecast with the actual test values\n",
    "f, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.scatter(restaurant_test.index, restaurant_test['CustomerCount'], color='r', label='Actual')\n",
    "fig = m.plot(test_forecast_df, ax=ax)\n",
    "ax.set_title(\"Prophet Forecast with Actuals\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Zoom In: January 2022 (All Hours) -----\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(restaurant_test.index, restaurant_test['CustomerCount'], color='r', label='Actual')\n",
    "fig = m.plot(test_forecast_df, ax=ax)\n",
    "ax.set_xbound(lower=pd.to_datetime('2022-01-01'), upper=pd.to_datetime('2022-02-01'))\n",
    "ax.set_ylim(0, 80)\n",
    "plt.suptitle('January 2022 Forecast vs Actuals')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# ----- Zoom In Further: First Week of January 2022 (All Hours) -----\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(restaurant_test.index, restaurant_test['CustomerCount'], color='r', label='Actual')\n",
    "fig = m.plot(test_forecast_df, ax=ax)\n",
    "lower_bound = pd.to_datetime('2022-01-01')\n",
    "upper_bound = pd.to_datetime('2022-01-08')\n",
    "ax.set_xbound(lower=lower_bound, upper=upper_bound)\n",
    "ax.set_ylim(0, 80)\n",
    "ax.set_title('First Week of January 2022 Forecast vs Actuals')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Compare Forecast vs. Actuals for Dynamically Identified Peak Hours -----\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(actual_peak_df['ds'], actual_peak_df['y'], \n",
    "            color='r', label='Actual Peak Hours', alpha=0.7)\n",
    "\n",
    "plt.plot(forecast_peak_df['ds'], forecast_peak_df['yhat'], \n",
    "         marker='o', linestyle='-', color='skyblue', label='Baseline Forecast')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Customer Count')\n",
    "plt.title('Baseline Model Forecast for Dynamically Identified Peak Hours')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Plot Prophet Components for the Test Forecast -----\n",
    "fig = m.plot_components(test_forecast_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Future Forecasting (baseline) --\n",
    "# Generate future data for the next 30 days at hourly frequency\n",
    "future = m.make_future_dataframe(periods=30*24, freq='h')\n",
    "forecast_future = m.predict(future)\n",
    "\n",
    "print(\"Future Forecast:\")\n",
    "display(forecast_future.head())\n",
    "\n",
    "# Plot the future forecast (historical data in black, forecast in blue)\n",
    "m.plot(forecast_future)\n",
    "plt.title(\"Future Forecast (Hourly)\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average forecast (yhat) per hour from the future forecast\n",
    "forecast_future['Hour'] = forecast_future['ds'].dt.hour\n",
    "\n",
    "future_hourly_avg = (\n",
    "    forecast_future\n",
    "    .groupby('Hour')['yhat']\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "future_hourly_avg_df = future_hourly_avg.reset_index(name='Avg Forecast (yhat)')\n",
    "\n",
    "display(\n",
    "    future_hourly_avg_df\n",
    "    .style\n",
    "    .set_caption(\"ðŸ“Š Baseline Model: Future Avg Forecast by Hour\")\n",
    "    .background_gradient(cmap='Blues')\n",
    "    .hide(axis='index')  \n",
    ")\n",
    "\n",
    "# Threshold-based peak hour selection\n",
    "threshold = 0.6 * future_hourly_avg.max()\n",
    "print(\"\\n Threshold for Peak Hours:\", round(threshold, 2))\n",
    "\n",
    "future_peak_hours = sorted([hour for hour, val in future_hourly_avg.items() if val >= threshold])\n",
    "print(\"\\n Dynamically Selected Peak Hours:\", future_peak_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Evaluate Error Metrics for All Test Data for the baseline -----\n",
    "mae_all = mean_absolute_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=test_forecast_df['yhat']\n",
    ")\n",
    "rmse_all = np.sqrt(mean_squared_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=test_forecast_df['yhat']\n",
    "))\n",
    "mape_all = mean_absolute_percentage_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=test_forecast_df['yhat']\n",
    ")\n",
    "\n",
    "print(\"Overall Test Data Metrics:\")\n",
    "print(\"MAE:\", mae_all)\n",
    "print(\"RMSE:\", rmse_all)\n",
    "print(\"MAPE:\", mape_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Evaluate Error Metrics for Peak Hours -----\n",
    "# Align the forecasts and actual values by their datetime 'ds' for peak hours\n",
    "actual_peak = actual_peak_df.set_index('ds')['y']\n",
    "predicted_peak = forecast_peak_df.set_index('ds')['yhat']\n",
    "\n",
    "mae_peak = mean_absolute_error(actual_peak, predicted_peak)\n",
    "rmse_peak = np.sqrt(mean_squared_error(actual_peak, predicted_peak))\n",
    "mape_peak = mean_absolute_percentage_error(actual_peak, predicted_peak)\n",
    "\n",
    "print(\"\\nPeak Hours Metrics:\")\n",
    "print(\"Baseline Peak Hours MAE:\", mae_peak)\n",
    "print(\"Baseline Peak Hours RMSE:\", rmse_peak)\n",
    "print(\"Baseline Peak Hours MAPE:\", mape_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your baseline model (m) for cross-validation.\n",
    "df_cv_baseline = cross_validation(m, initial='730 days', period='180 days', horizon='365 days')\n",
    "df_p_baseline = performance_metrics(df_cv_baseline)\n",
    "\n",
    "print(\"Cross-Validation Performance Metrics for Baseline Model:\")\n",
    "df_p_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cross-Validation Summary for baseline\n",
    "print(\"Cross-Validation Performance Metrics (Average) for Baseline Model (Overall):\")\n",
    "available_metrics = ['rmse', 'mae', 'mape', 'smape']\n",
    "\n",
    "for metric in available_metrics:\n",
    "    if metric in df_p_baseline.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_baseline[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Peak Hours CV Metrics for baseline\n",
    "df_cv_baseline['Hour'] = df_cv_baseline['ds'].dt.hour\n",
    "df_cv_baseline_peak = df_cv_baseline[df_cv_baseline['Hour'].isin(peak_hours_dynamic)]\n",
    "\n",
    "rmse_peak = np.sqrt(mean_squared_error(df_cv_baseline_peak['y'], df_cv_baseline_peak['yhat']))\n",
    "mae_peak = mean_absolute_error(df_cv_baseline_peak['y'], df_cv_baseline_peak['yhat'])\n",
    "mape_peak = mean_absolute_percentage_error(df_cv_baseline_peak['y'], df_cv_baseline_peak['yhat'])\n",
    "\n",
    "# SMAPE custom calculation\n",
    "smape_peak = 100 * np.mean(\n",
    "    2 * np.abs(df_cv_baseline_peak['yhat'] - df_cv_baseline_peak['y']) /\n",
    "    (np.abs(df_cv_baseline_peak['yhat']) + np.abs(df_cv_baseline_peak['y']))\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validation Performance Metrics (Average) for Baseline Model (Peak Hours Only):\")\n",
    "print(f\"RMSE: {rmse_peak:.3f}\")\n",
    "print(f\"MAE: {mae_peak:.3f}\")\n",
    "print(f\"MAPE: {mape_peak:.3f}\")\n",
    "print(f\"SMAPE: {smape_peak:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "    'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    'changepoint_range': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "m_best_r1, best_params, tuning_results = tune_prophet_model(\n",
    "    train_df=restaurant_train_prophet,\n",
    "    test_df=restaurant_test_prophet,\n",
    "    param_grid=param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Test Set Forecasting with the Tuned Model --\n",
    "restaurant_test_fcst_best_r1 = forecast_with_model_r1(m_best_r1, restaurant_test_prophet)\n",
    "restaurant_test_fcst_best_r1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with your analysis using the tuned forecasts:\n",
    "restaurant_test_fcst_best_r1['Hour'] = restaurant_test_fcst_best_r1['ds'].dt.hour\n",
    "hourly_avg_best_r1 = restaurant_test_fcst_best_r1.groupby('Hour')['yhat'].mean()\n",
    "print(\"\\nAverage Forecast by Hour (Tuned Model):\")\n",
    "print(hourly_avg_best_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select Peak Hours using the forecasted test set and actual test data ---\n",
    "\n",
    "(\n",
    "    peak_hours_dynamic_best_r1,           \n",
    "    threshold_best_r1,                    \n",
    "    tuned_peak_fcst_dynamic_best_r1,      \n",
    "    restaurant_test_prophet_peak_dynamic_best_r1,  \n",
    "    hourly_avg_best_r1                   \n",
    ") = select_peak_hours(\n",
    "    restaurant_test_fcst_best_r1,         \n",
    "    restaurant_test_prophet,              \n",
    "    threshold_ratio=0.6                  \n",
    ")\n",
    "\n",
    "# View results\n",
    "print(\"Threshold for Peak Hours:\", threshold_best_r1)\n",
    "print(\"Dynamically Identified Peak Hours:\", peak_hours_dynamic_best_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate error metrics for the tuned model (overall)\n",
    "mae_all_best_r1 = mean_absolute_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=restaurant_test_fcst_best_r1['yhat']\n",
    ")\n",
    "rmse_all_best_r1 = np.sqrt(mean_squared_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=restaurant_test_fcst_best_r1['yhat']\n",
    "))\n",
    "mape_all_best_r1 = mean_absolute_percentage_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=restaurant_test_fcst_best_r1['yhat']\n",
    ")\n",
    "print(\"\\nTuned Model Overall Test Data Metrics:\")\n",
    "print(\"MAE:\", mae_all_best_r1)\n",
    "print(\"RMSE:\", rmse_all_best_r1)\n",
    "print(\"MAPE:\", mape_all_best_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate error metrics for the tuned model ( peak hours)\n",
    "actual_peak_best_r1 = restaurant_test_prophet_peak_dynamic_best_r1.set_index('ds')['y']\n",
    "predicted_peak_best_r1 = tuned_peak_fcst_dynamic_best_r1.set_index('ds')['yhat']\n",
    "mae_peak_best_r1 = mean_absolute_error(actual_peak_best_r1, predicted_peak_best_r1)\n",
    "rmse_peak_best_r1 = np.sqrt(mean_squared_error(actual_peak_best_r1, predicted_peak_best_r1))\n",
    "mape_peak_best_r1 = mean_absolute_percentage_error(actual_peak_best_r1, predicted_peak_best_r1)\n",
    "print(\"\\nTuned Model Peak Hours Metrics:\")\n",
    "print(\"MAE:\", mae_peak_best_r1)\n",
    "print(\"RMSE:\", rmse_peak_best_r1)\n",
    "print(\"MAPE:\", mape_peak_best_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Cross_validation----\n",
    "df_cv_r1 = cross_validation(m_best_r1, initial='730 days', period='180 days', horizon='365 days')\n",
    "df_p_r1 = performance_metrics(df_cv_r1)\n",
    "\n",
    "print(\"\\nCross-Validation Performance Metrics (First 5 rows) for Tuned Model (Refinement 1):\")\n",
    "df_p_r1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation Summary for overall\n",
    "available_metrics = ['rmse', 'mae', 'mape', 'smape']\n",
    "\n",
    "for metric in available_metrics:\n",
    "    if metric in df_p_r1.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r1[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Hours CV Metrics\n",
    "df_cv_r1['hour'] = df_cv_r1['ds'].dt.hour\n",
    "df_cv_r1_peak = df_cv_r1[df_cv_r1['hour'].isin(peak_hours_dynamic_best_r1)]\n",
    "df_p_r1_peak = performance_metrics(df_cv_r1_peak)\n",
    "\n",
    "# Display average metrics\n",
    "print(\"\\nCross-Validation Performance Metrics (Average) for Peak Hours Only:\")\n",
    "for metric in ['rmse', 'mae', 'mape', 'smape']:\n",
    "    if metric in df_p_r1_peak.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r1_peak[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30-day future forecast using Refinement 1 model\n",
    "forecast_future_r1, future_hourly_avg_r1, threshold_r1, future_peak_hours_r1 = forecast_future_with_model_r1(\n",
    "    m_best_r1, days=30, freq='h', threshold_ratio=0.6)\n",
    "\n",
    "# View first few rows of the forecast\n",
    "print(\"Future Forecast (Refinement 1):\")\n",
    "display(forecast_future_r1.head())\n",
    "\n",
    "#Future forecast\n",
    "# Convert Series to clean DataFrame for display\n",
    "future_hourly_avg_r1_df = future_hourly_avg_r1.reset_index(name='Avg Forecast (yhat)')\n",
    "\n",
    "# Display with heatmap-style coloring and no index\n",
    "display(\n",
    "    future_hourly_avg_r1_df\n",
    "    .style\n",
    "    .set_caption(\"ðŸ“Š Refinement 1: Future Avg Forecast by Hour\")\n",
    "    .hide(axis='index')  # Hides the index column\n",
    "    .background_gradient(cmap='Blues')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "start_year = restaurant_train.index.min().year\n",
    "end_year = restaurant_test.index.max().year\n",
    "holiday_df = prepare_holiday_df(start_year, end_year)\n",
    "\n",
    "print(\"Holiday Data:\")\n",
    "display(holiday_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Training and Test Data\n",
    "restaurant_train_prophet = restaurant_train.reset_index().rename(\n",
    "    columns={'Timestamp': 'ds', 'CustomerCount': 'y'}\n",
    ")\n",
    "restaurant_test_prophet = restaurant_test.reset_index().rename(\n",
    "    columns={'Timestamp': 'ds', 'CustomerCount': 'y'}\n",
    ")\n",
    "\n",
    "restaurant_train_prophet['hour'] = pd.to_datetime(restaurant_train_prophet['ds']).dt.hour\n",
    "restaurant_test_prophet['hour'] = pd.to_datetime(restaurant_test_prophet['ds']).dt.hour\n",
    "\n",
    "print(\"Training Data Columns:\", restaurant_train_prophet.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Hyperparameter Grid\n",
    "param_grid_r2 = {\n",
    "    'changepoint_prior_scale': [0.01, 0.1],\n",
    "    'seasonality_prior_scale': [0.1, 1.0],\n",
    "    'seasonality_mode': ['additive', 'multiplicative']\n",
    "}\n",
    "\n",
    "#Tune and Train Final R2 Model\n",
    "m_best_r2, best_params_r2, tuning_results_r2 = tune_prophet_model_r2(\n",
    "    train_df=restaurant_train_prophet,\n",
    "    test_df=restaurant_test_prophet,\n",
    "    holiday_df=holiday_df,\n",
    "    param_grid=param_grid_r2\n",
    ")\n",
    "\n",
    "print(\"Best Hyperparameters (Refinement 2):/n\")\n",
    "print(best_params_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_test_fcst_best_r2 = forecast_with_model_r2(m_best_r2, restaurant_test_prophet)\n",
    "display(restaurant_test_fcst_best_r2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    peak_hours_dynamic_best_r2,\n",
    "    threshold_best_r2,\n",
    "    tuned_peak_fcst_dynamic_best_r2,\n",
    "    restaurant_test_prophet_peak_dynamic_best_r2,\n",
    "    hourly_avg_best_r2\n",
    ") = select_peak_hours_r2(restaurant_test_fcst_best_r2, restaurant_test_prophet, threshold_ratio=0.6)\n",
    "\n",
    "print(\"Threshold:\", threshold_best_r2)\n",
    "print(\"Peak Hours (Refinement 2):\", peak_hours_dynamic_best_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate error metrics for the tuned model 2 (overall)\n",
    "overall_mae_r2 = mean_absolute_error(restaurant_test['CustomerCount'], restaurant_test_fcst_best_r2['yhat'])\n",
    "overall_rmse_r2 = np.sqrt(mean_squared_error(restaurant_test['CustomerCount'], restaurant_test_fcst_best_r2['yhat']))\n",
    "overall_mape_r2 = mean_absolute_percentage_error(restaurant_test['CustomerCount'], restaurant_test_fcst_best_r2['yhat'])\n",
    "\n",
    "print(\"\\nTuned Model Overall Test Data Metrics (Refinement 2):\")\n",
    "print(\"MAE:\", overall_mae_r2)\n",
    "print(\"RMSE:\", overall_rmse_r2)\n",
    "print(\"MAPE:\", overall_mape_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in restaurant_test:\")\n",
    "print(restaurant_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rename 'y' to 'CustomerCount' BEFORE calling the function\n",
    "restaurant_test_prophet_renamed = restaurant_test_prophet.rename(columns={'y': 'CustomerCount'})\n",
    "\n",
    "# Step 2: Now call the function with the renamed DataFrame\n",
    "metrics_r2 = evaluate_metrics_r2(\n",
    "    forecast_df=restaurant_test_fcst_best_r2,\n",
    "    actual_df=restaurant_test_prophet_renamed\n",
    ")\n",
    "\n",
    "# Step 3: Extract and print peak metrics\n",
    "peak_mae_r2 = metrics_r2['peak_hours']['MAE']\n",
    "peak_rmse_r2 = metrics_r2['peak_hours']['RMSE']\n",
    "peak_mape_r2 = metrics_r2['peak_hours']['MAPE']\n",
    "\n",
    "print(\"\\nTuned Model Peak Hour Test Data Metrics (Refinement 2):\")\n",
    "print(\"MAE:\", peak_mae_r2)\n",
    "print(\"RMSE:\", peak_rmse_r2)\n",
    "print(\"MAPE:\", peak_mape_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_r2, df_p_r2 = cross_validate_model_r2(m_best_r2)\n",
    "\n",
    "print(\"Cross-Validation (First 5 rows):\")\n",
    "display(df_p_r2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation Summary for overall\n",
    "print(\"\\nCross-Validation Summary (Refinement 2):\")\n",
    "for metric in ['rmse', 'mae', 'mape', 'smape']:\n",
    "    if metric in df_p_r2.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r2[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Peak Hours CV Metrics for Refinement 2 ---\n",
    "\n",
    "df_cv_r2['hour'] = df_cv_r2['ds'].dt.hour\n",
    "df_cv_r2_peak = df_cv_r2[df_cv_r2['hour'].isin(peak_hours_dynamic_best_r2)]\n",
    "\n",
    "df_p_r2_peak = performance_metrics(df_cv_r2_peak)\n",
    "\n",
    "# Display average metrics for peak hour performance\n",
    "print(\"\\nCross-Validation Performance Metrics (Average) for Peak Hours Only - Refinement 2:\")\n",
    "for metric in ['rmse', 'mae', 'mape', 'smape']:\n",
    "    if metric in df_p_r2_peak.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r2_peak[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_test_fcst_best_r2 = forecast_with_model_r2(m_best_r2, restaurant_test_prophet)\n",
    "restaurant_test_fcst_best_r2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30-day future forecast using Refinement 2 model\n",
    "forecast_future_r2, future_hourly_avg_r2, threshold_r2, future_peak_hours_r2 = forecast_future_with_model_r2(\n",
    "    m_best_r2, days=30, freq='h', threshold_ratio=0.6)\n",
    "\n",
    "# View first few rows of the forecast\n",
    "print(\"Future Forecast (Refinement 2):\")\n",
    "display(forecast_future_r2.head())\n",
    "\n",
    "# Plot forecast\n",
    "m_best_r2.plot(forecast_future_r2)\n",
    "plt.title(\"Future Forecast (Hourly) - Tuned + Holiday + Hour Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average forecast (yhat) per hour\n",
    "forecast_future_r2['Hour'] = forecast_future_r2['ds'].dt.hour\n",
    "future_hourly_avg_r2 = forecast_future_r2.groupby('Hour')['yhat'].mean().reset_index()\n",
    "\n",
    "# Round the forecast values for clarity\n",
    "future_hourly_avg_r2['yhat'] = future_hourly_avg_r2['yhat'].round(2)\n",
    "\n",
    "# Rename columns for nicer display\n",
    "future_hourly_avg_r2.columns = ['Hour of Day', 'Average Forecasted Customers']\n",
    "\n",
    "# Display as a pretty table with hidden index\n",
    "print(\"\\nðŸ“Š Future Average Forecast by Hour (Refinement 2):\")\n",
    "\n",
    "display(\n",
    "    future_hourly_avg_r2\n",
    "    .style\n",
    "    .set_caption(\"Average Hourly Forecast\")\n",
    "    .hide(axis='index')  # Hide index here\n",
    "    .background_gradient(cmap='Blues')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
