{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory (optional during development)\n",
    "import os\n",
    "os.chdir('/Users/sudishmakarki/My_project2')  # only if needed\n",
    "print(\" Working directory:\", os.getcwd())\n",
    "\n",
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom Functions\n",
    "from models.data_interpolation import (\n",
    "    load_data,\n",
    "    preprocess_data,\n",
    "    split_train_test,\n",
    "    generate_time_series_splits\n",
    ")\n",
    "\n",
    "from models.model_prophet import (\n",
    "    prepare_prophet_data,\n",
    "    train_baseline_prophet,\n",
    "    forecast_with_model,\n",
    "    calculate_peak_hours,\n",
    "    evaluate_metrics,\n",
    "    cross_validate_baseline\n",
    ")\n",
    "\n",
    "from models.model_prophet import (\n",
    "    tune_prophet_model,\n",
    "    forecast_with_model_r1,\n",
    "    select_peak_hours,\n",
    "    evaluate_tuned_model_metrics,\n",
    "    cross_validate_tuned_r1\n",
    ")\n",
    "\n",
    "from models.model_prophet import (\n",
    "    prepare_holiday_df,\n",
    "    tune_prophet_model_r2,\n",
    "    forecast_with_model_r2,\n",
    "    select_peak_hours_r2,\n",
    "    evaluate_metrics_r2,\n",
    "    cross_validate_model_r2,\n",
    "    forecast_future_with_model_r2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess\n",
    "df = load_data('data/RestaurantData.csv')\n",
    "df_clean = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "restaurant_train, restaurant_test = split_train_test(df_clean, split_date='2022-01-01')\n",
    "# Format for Prophet\n",
    "restaurant_train_prophet, restaurant_test_prophet = prepare_prophet_data(restaurant_train, restaurant_test)\n",
    "# Train the baseline Prophet model\n",
    "m = train_baseline_prophet(restaurant_train_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Test Set Forecasting --\n",
    "# Predict on the test set and display the first few rows\n",
    "test_forecast_df = forecast_with_model(m, restaurant_test_prophet)\n",
    "print(\"Forecast on Test Set (first 5 rows):\")\n",
    "test_forecast_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average forecast per hour\n",
    "hourly_avg = test_forecast_df.groupby('Hour')['yhat'].mean()\n",
    "print(\"\\nAverage Forecast by Hour:\")\n",
    "display(hourly_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_hours_dynamic, hourly_avg, threshold = calculate_peak_hours(test_forecast_df)\n",
    "\n",
    "print(\"\\nThreshold for Peak Hours:\", threshold)\n",
    "print(\"\\nDynamically Identified Peak Hours:\", peak_hours_dynamic)\n",
    "\n",
    "# Filter forecast and actuals for dynamically identified peak hours\n",
    "forecast_peak_df = test_forecast_df[test_forecast_df['Hour'].isin(peak_hours_dynamic)]\n",
    "actual_peak_df = restaurant_test_prophet[restaurant_test_prophet['Hour'].isin(peak_hours_dynamic)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Average forecasted customer count by hour -----\n",
    "plt.figure(figsize=(10, 5))\n",
    "hourly_avg.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Average Forecasted Customer Count by Hour\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Average Forecast (yhat)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Compare Forecast to Actuals (All Hours) -----\n",
    "# Plot the forecast with the actual test values\n",
    "f, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.scatter(restaurant_test.index, restaurant_test['CustomerCount'], color='r', label='Actual')\n",
    "fig = m.plot(test_forecast_df, ax=ax)\n",
    "ax.set_title(\"Prophet Forecast with Actuals\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Zoom In: January 2022 (All Hours) -----\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(restaurant_test.index, restaurant_test['CustomerCount'], color='r', label='Actual')\n",
    "fig = m.plot(test_forecast_df, ax=ax)\n",
    "ax.set_xbound(lower=pd.to_datetime('2022-01-01'), upper=pd.to_datetime('2022-02-01'))\n",
    "ax.set_ylim(0, 80)\n",
    "plt.suptitle('January 2022 Forecast vs Actuals')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# ----- Zoom In Further: First Week of January 2022 (All Hours) -----\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.scatter(restaurant_test.index, restaurant_test['CustomerCount'], color='r', label='Actual')\n",
    "fig = m.plot(test_forecast_df, ax=ax)\n",
    "lower_bound = pd.to_datetime('2022-01-01')\n",
    "upper_bound = pd.to_datetime('2022-01-08')\n",
    "ax.set_xbound(lower=lower_bound, upper=upper_bound)\n",
    "ax.set_ylim(0, 80)\n",
    "ax.set_title('First Week of January 2022 Forecast vs Actuals')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Compare Forecast vs. Actuals for Dynamically Identified Peak Hours -----\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(actual_peak_df['ds'], actual_peak_df['y'], \n",
    "            color='r', label='Actual Peak Hours', alpha=0.7)\n",
    "\n",
    "plt.plot(forecast_peak_df['ds'], forecast_peak_df['yhat'], \n",
    "         marker='o', linestyle='-', color='skyblue', label='Baseline Forecast')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Customer Count')\n",
    "plt.title('Baseline Model Forecast for Dynamically Identified Peak Hours')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Plot Prophet Components for the Test Forecast -----\n",
    "fig = m.plot_components(test_forecast_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Future Forecasting (baseline) --\n",
    "# Generate future data for the next 30 days at hourly frequency\n",
    "future = m.make_future_dataframe(periods=30*24, freq='h')\n",
    "forecast_future = m.predict(future)\n",
    "\n",
    "print(\"Future Forecast:\")\n",
    "display(forecast_future.head())\n",
    "\n",
    "# Plot the future forecast (historical data in black, forecast in blue)\n",
    "m.plot(forecast_future)\n",
    "plt.title(\"Future Forecast (Hourly)\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the average forecast (yhat) per hour from the future forecast\n",
    "forecast_future['Hour'] = forecast_future['ds'].dt.hour\n",
    "future_hourly_avg = forecast_future.groupby('Hour')['yhat'].mean()\n",
    "print(\"\\nFuture Average Forecast by Hour:\")\n",
    "print(future_hourly_avg)\n",
    "\n",
    "# Define a threshold based on the maximum forecast value (e.g., 60% of max)\n",
    "threshold = 0.6 * future_hourly_avg.max()\n",
    "print(\"\\nThreshold for Peak Hours:\", threshold)\n",
    "\n",
    "# Dynamically select all hours where the forecast meets or exceeds the threshold\n",
    "future_peak_hours = sorted([hour for hour, demand in future_hourly_avg.items() if demand >= threshold])\n",
    "print(\"\\nDynamically Selected Peak Hours:\", future_peak_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Evaluate Error Metrics for All Test Data for the baseline -----\n",
    "mae_all = mean_absolute_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=test_forecast_df['yhat']\n",
    ")\n",
    "rmse_all = np.sqrt(mean_squared_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=test_forecast_df['yhat']\n",
    "))\n",
    "mape_all = mean_absolute_percentage_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=test_forecast_df['yhat']\n",
    ")\n",
    "\n",
    "print(\"Overall Test Data Metrics:\")\n",
    "print(\"MAE:\", mae_all)\n",
    "print(\"RMSE:\", rmse_all)\n",
    "print(\"MAPE:\", mape_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Evaluate Error Metrics for Peak Hours -----\n",
    "# Align the forecasts and actual values by their datetime 'ds' for peak hours\n",
    "actual_peak = actual_peak_df.set_index('ds')['y']\n",
    "predicted_peak = forecast_peak_df.set_index('ds')['yhat']\n",
    "\n",
    "mae_peak = mean_absolute_error(actual_peak, predicted_peak)\n",
    "rmse_peak = np.sqrt(mean_squared_error(actual_peak, predicted_peak))\n",
    "mape_peak = mean_absolute_percentage_error(actual_peak, predicted_peak)\n",
    "\n",
    "print(\"\\nPeak Hours Metrics:\")\n",
    "print(\"Baseline Peak Hours MAE:\", mae_peak)\n",
    "print(\"Baseline Peak Hours RMSE:\", rmse_peak)\n",
    "print(\"Baseline Peak Hours MAPE:\", mape_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your baseline model (m) for cross-validation.\n",
    "df_cv_baseline = cross_validation(m, initial='730 days', period='180 days', horizon='365 days')\n",
    "df_p_baseline = performance_metrics(df_cv_baseline)\n",
    "\n",
    "print(\"Cross-Validation Performance Metrics for Baseline Model:\")\n",
    "df_p_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cross-Validation Summary for baseline\n",
    "print(\"Cross-Validation Performance Metrics (Average) for Baseline Model (Overall):\")\n",
    "available_metrics = ['rmse', 'mae', 'mape', 'smape']\n",
    "\n",
    "for metric in available_metrics:\n",
    "    if metric in df_p_baseline.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_baseline[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Peak Hours CV Metrics for baseline\n",
    "df_cv_baseline['Hour'] = df_cv_baseline['ds'].dt.hour\n",
    "df_cv_baseline_peak = df_cv_baseline[df_cv_baseline['Hour'].isin(peak_hours_dynamic)]\n",
    "\n",
    "rmse_peak = np.sqrt(mean_squared_error(df_cv_baseline_peak['y'], df_cv_baseline_peak['yhat']))\n",
    "mae_peak = mean_absolute_error(df_cv_baseline_peak['y'], df_cv_baseline_peak['yhat'])\n",
    "mape_peak = mean_absolute_percentage_error(df_cv_baseline_peak['y'], df_cv_baseline_peak['yhat'])\n",
    "\n",
    "# SMAPE custom calculation\n",
    "smape_peak = 100 * np.mean(\n",
    "    2 * np.abs(df_cv_baseline_peak['yhat'] - df_cv_baseline_peak['y']) /\n",
    "    (np.abs(df_cv_baseline_peak['yhat']) + np.abs(df_cv_baseline_peak['y']))\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validation Performance Metrics (Average) for Baseline Model (Peak Hours Only):\")\n",
    "print(f\"RMSE: {rmse_peak:.3f}\")\n",
    "print(f\"MAE: {mae_peak:.3f}\")\n",
    "print(f\"MAPE: {mape_peak:.3f}\")\n",
    "print(f\"SMAPE: {smape_peak:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "    'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    'changepoint_range': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "m_best_r1, best_params, tuning_results = tune_prophet_model(\n",
    "    train_df=restaurant_train_prophet,\n",
    "    test_df=restaurant_test_prophet,\n",
    "    param_grid=param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Test Set Forecasting with the Tuned Model --\n",
    "restaurant_test_fcst_best_r1 = forecast_with_model_r1(m_best_r1, restaurant_test_prophet)\n",
    "restaurant_test_fcst_best_r1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with your analysis using the tuned forecasts:\n",
    "restaurant_test_fcst_best_r1['Hour'] = restaurant_test_fcst_best_r1['ds'].dt.hour\n",
    "hourly_avg_best_r1 = restaurant_test_fcst_best_r1.groupby('Hour')['yhat'].mean()\n",
    "print(\"\\nAverage Forecast by Hour (Tuned Model):\")\n",
    "print(hourly_avg_best_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select Peak Hours using the forecasted test set and actual test data ---\n",
    "\n",
    "(\n",
    "    peak_hours_dynamic_best_r1,           \n",
    "    threshold_best_r1,                    \n",
    "    tuned_peak_fcst_dynamic_best_r1,      \n",
    "    restaurant_test_prophet_peak_dynamic_best_r1,  \n",
    "    hourly_avg_best_r1                   \n",
    ") = select_peak_hours(\n",
    "    restaurant_test_fcst_best_r1,         \n",
    "    restaurant_test_prophet,              \n",
    "    threshold_ratio=0.6                  \n",
    ")\n",
    "\n",
    "# View results\n",
    "print(\"Threshold for Peak Hours:\", threshold_best_r1)\n",
    "print(\"Dynamically Identified Peak Hours:\", peak_hours_dynamic_best_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate error metrics for the tuned model (overall)\n",
    "mae_all_best_r1 = mean_absolute_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=restaurant_test_fcst_best_r1['yhat']\n",
    ")\n",
    "rmse_all_best_r1 = np.sqrt(mean_squared_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=restaurant_test_fcst_best_r1['yhat']\n",
    "))\n",
    "mape_all_best_r1 = mean_absolute_percentage_error(\n",
    "    y_true=restaurant_test['CustomerCount'],\n",
    "    y_pred=restaurant_test_fcst_best_r1['yhat']\n",
    ")\n",
    "print(\"\\nTuned Model Overall Test Data Metrics:\")\n",
    "print(\"MAE:\", mae_all_best_r1)\n",
    "print(\"RMSE:\", rmse_all_best_r1)\n",
    "print(\"MAPE:\", mape_all_best_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate error metrics for the tuned model ( peak hours)\n",
    "actual_peak_best_r1 = restaurant_test_prophet_peak_dynamic_best_r1.set_index('ds')['y']\n",
    "predicted_peak_best_r1 = tuned_peak_fcst_dynamic_best_r1.set_index('ds')['yhat']\n",
    "mae_peak_best_r1 = mean_absolute_error(actual_peak_best_r1, predicted_peak_best_r1)\n",
    "rmse_peak_best_r1 = np.sqrt(mean_squared_error(actual_peak_best_r1, predicted_peak_best_r1))\n",
    "mape_peak_best_r1 = mean_absolute_percentage_error(actual_peak_best_r1, predicted_peak_best_r1)\n",
    "print(\"\\nTuned Model Peak Hours Metrics:\")\n",
    "print(\"MAE:\", mae_peak_best_r1)\n",
    "print(\"RMSE:\", rmse_peak_best_r1)\n",
    "print(\"MAPE:\", mape_peak_best_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Cross_validation----\n",
    "df_cv_r1 = cross_validation(m_best_r1, initial='730 days', period='180 days', horizon='365 days')\n",
    "df_p_r1 = performance_metrics(df_cv_r1)\n",
    "\n",
    "print(\"\\nCross-Validation Performance Metrics (First 5 rows) for Tuned Model (Refinement 1):\")\n",
    "df_p_r1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation Summary for overall\n",
    "available_metrics = ['rmse', 'mae', 'mape', 'smape']\n",
    "\n",
    "for metric in available_metrics:\n",
    "    if metric in df_p_r1.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r1[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Hours CV Metrics\n",
    "df_cv_r1['hour'] = df_cv_r1['ds'].dt.hour\n",
    "df_cv_r1_peak = df_cv_r1[df_cv_r1['hour'].isin(peak_hours_dynamic_best_r1)]\n",
    "df_p_r1_peak = performance_metrics(df_cv_r1_peak)\n",
    "\n",
    "# Display average metrics\n",
    "print(\"\\nCross-Validation Performance Metrics (Average) for Peak Hours Only:\")\n",
    "for metric in ['rmse', 'mae', 'mape', 'smape']:\n",
    "    if metric in df_p_r1_peak.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r1_peak[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = restaurant_train.index.min().year\n",
    "end_year = restaurant_test.index.max().year\n",
    "holiday_df = prepare_holiday_df(start_year, end_year)\n",
    "\n",
    "print(\"Holiday Data:\")\n",
    "display(holiday_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Training and Test Data\n",
    "restaurant_train_prophet = restaurant_train.reset_index().rename(\n",
    "    columns={'Timestamp': 'ds', 'CustomerCount': 'y'}\n",
    ")\n",
    "restaurant_test_prophet = restaurant_test.reset_index().rename(\n",
    "    columns={'Timestamp': 'ds', 'CustomerCount': 'y'}\n",
    ")\n",
    "\n",
    "restaurant_train_prophet['hour'] = pd.to_datetime(restaurant_train_prophet['ds']).dt.hour\n",
    "restaurant_test_prophet['hour'] = pd.to_datetime(restaurant_test_prophet['ds']).dt.hour\n",
    "\n",
    "print(\"Training Data Columns:\", restaurant_train_prophet.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning with Holidays and External Regressor (hour):\n",
      "Params: {'changepoint_prior_scale': 0.01, 'seasonality_prior_scale': 0.1, 'seasonality_mode': 'additive'} --> RMSE: 7.6868, MAE: 6.0952, Composite: 13.7820\n",
      "Params: {'changepoint_prior_scale': 0.01, 'seasonality_prior_scale': 0.1, 'seasonality_mode': 'multiplicative'} --> RMSE: 7.8264, MAE: 6.2069, Composite: 14.0333\n",
      "Params: {'changepoint_prior_scale': 0.01, 'seasonality_prior_scale': 1.0, 'seasonality_mode': 'additive'} --> RMSE: 7.6873, MAE: 6.0943, Composite: 13.7815\n",
      "Params: {'changepoint_prior_scale': 0.01, 'seasonality_prior_scale': 1.0, 'seasonality_mode': 'multiplicative'} --> RMSE: 7.8299, MAE: 6.2092, Composite: 14.0391\n",
      "Params: {'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 0.1, 'seasonality_mode': 'additive'} --> RMSE: 7.7168, MAE: 6.0984, Composite: 13.8151\n",
      "Params: {'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 0.1, 'seasonality_mode': 'multiplicative'} --> RMSE: 7.8444, MAE: 6.2104, Composite: 14.0547\n",
      "Params: {'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 1.0, 'seasonality_mode': 'additive'} --> RMSE: 7.7155, MAE: 6.0978, Composite: 13.8132\n",
      "Params: {'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 1.0, 'seasonality_mode': 'multiplicative'} --> RMSE: 7.8462, MAE: 6.2123, Composite: 14.0585\n",
      "Best Hyperparameters (Refinement 2):/n\n",
      "changepoint_prior_scale         0.01\n",
      "seasonality_prior_scale          1.0\n",
      "seasonality_mode            additive\n",
      "rmse                        7.687272\n",
      "mae                         6.094272\n",
      "composite                  13.781544\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Define Hyperparameter Grid\n",
    "param_grid_r2 = {\n",
    "    'changepoint_prior_scale': [0.01, 0.1],\n",
    "    'seasonality_prior_scale': [0.1, 1.0],\n",
    "    'seasonality_mode': ['additive', 'multiplicative']\n",
    "}\n",
    "\n",
    "#Tune and Train Final R2 Model\n",
    "m_best_r2, best_params_r2, tuning_results_r2 = tune_prophet_model_r2(\n",
    "    train_df=restaurant_train_prophet,\n",
    "    test_df=restaurant_test_prophet,\n",
    "    holiday_df=holiday_df,\n",
    "    param_grid=param_grid_r2\n",
    ")\n",
    "\n",
    "print(\"Best Hyperparameters (Refinement 2):/n\")\n",
    "print(best_params_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>Boxing Day</th>\n",
       "      <th>Boxing Day_lower</th>\n",
       "      <th>Boxing Day_upper</th>\n",
       "      <th>Boxing Day (observed)</th>\n",
       "      <th>Boxing Day (observed)_lower</th>\n",
       "      <th>Boxing Day (observed)_upper</th>\n",
       "      <th>Christmas Day</th>\n",
       "      <th>Christmas Day_lower</th>\n",
       "      <th>Christmas Day_upper</th>\n",
       "      <th>Christmas Day (observed)</th>\n",
       "      <th>Christmas Day (observed)_lower</th>\n",
       "      <th>Christmas Day (observed)_upper</th>\n",
       "      <th>Good Friday</th>\n",
       "      <th>Good Friday_lower</th>\n",
       "      <th>Good Friday_upper</th>\n",
       "      <th>May Day</th>\n",
       "      <th>May Day_lower</th>\n",
       "      <th>May Day_upper</th>\n",
       "      <th>New Year's Day</th>\n",
       "      <th>New Year's Day_lower</th>\n",
       "      <th>New Year's Day_upper</th>\n",
       "      <th>New Year's Day (observed)</th>\n",
       "      <th>New Year's Day (observed)_lower</th>\n",
       "      <th>New Year's Day (observed)_upper</th>\n",
       "      <th>Platinum Jubilee of Elizabeth II</th>\n",
       "      <th>Platinum Jubilee of Elizabeth II_lower</th>\n",
       "      <th>Platinum Jubilee of Elizabeth II_upper</th>\n",
       "      <th>Spring Bank Holiday</th>\n",
       "      <th>Spring Bank Holiday_lower</th>\n",
       "      <th>Spring Bank Holiday_upper</th>\n",
       "      <th>State Funeral of Queen Elizabeth II</th>\n",
       "      <th>State Funeral of Queen Elizabeth II_lower</th>\n",
       "      <th>State Funeral of Queen Elizabeth II_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>daily</th>\n",
       "      <th>daily_lower</th>\n",
       "      <th>daily_upper</th>\n",
       "      <th>extra_regressors_additive</th>\n",
       "      <th>extra_regressors_additive_lower</th>\n",
       "      <th>extra_regressors_additive_upper</th>\n",
       "      <th>holidays</th>\n",
       "      <th>holidays_lower</th>\n",
       "      <th>holidays_upper</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_lower</th>\n",
       "      <th>hour_upper</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>20.300941</td>\n",
       "      <td>9.988873</td>\n",
       "      <td>28.931039</td>\n",
       "      <td>20.300941</td>\n",
       "      <td>20.300941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.114266</td>\n",
       "      <td>-1.114266</td>\n",
       "      <td>-1.114266</td>\n",
       "      <td>-14.096575</td>\n",
       "      <td>-14.096575</td>\n",
       "      <td>-14.096575</td>\n",
       "      <td>1.595472</td>\n",
       "      <td>1.595472</td>\n",
       "      <td>1.595472</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>1.595472</td>\n",
       "      <td>1.595472</td>\n",
       "      <td>1.595472</td>\n",
       "      <td>2.989836</td>\n",
       "      <td>2.989836</td>\n",
       "      <td>2.989836</td>\n",
       "      <td>-2.918688</td>\n",
       "      <td>-2.918688</td>\n",
       "      <td>-2.918688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.186675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>20.301053</td>\n",
       "      <td>9.602739</td>\n",
       "      <td>29.277493</td>\n",
       "      <td>20.301053</td>\n",
       "      <td>20.301053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.251013</td>\n",
       "      <td>-0.251013</td>\n",
       "      <td>-0.251013</td>\n",
       "      <td>-13.016521</td>\n",
       "      <td>-13.016521</td>\n",
       "      <td>-13.016521</td>\n",
       "      <td>1.456735</td>\n",
       "      <td>1.456735</td>\n",
       "      <td>1.456735</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>1.456735</td>\n",
       "      <td>1.456735</td>\n",
       "      <td>1.456735</td>\n",
       "      <td>2.908948</td>\n",
       "      <td>2.908948</td>\n",
       "      <td>2.908948</td>\n",
       "      <td>-2.915864</td>\n",
       "      <td>-2.915864</td>\n",
       "      <td>-2.915864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.050040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>20.301166</td>\n",
       "      <td>11.238112</td>\n",
       "      <td>31.089324</td>\n",
       "      <td>20.301166</td>\n",
       "      <td>20.301166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476709</td>\n",
       "      <td>0.476709</td>\n",
       "      <td>0.476709</td>\n",
       "      <td>-12.054215</td>\n",
       "      <td>-12.054215</td>\n",
       "      <td>-12.054215</td>\n",
       "      <td>1.317998</td>\n",
       "      <td>1.317998</td>\n",
       "      <td>1.317998</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>1.317998</td>\n",
       "      <td>1.317998</td>\n",
       "      <td>1.317998</td>\n",
       "      <td>2.810275</td>\n",
       "      <td>2.810275</td>\n",
       "      <td>2.810275</td>\n",
       "      <td>-2.913039</td>\n",
       "      <td>-2.913039</td>\n",
       "      <td>-2.913039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.777874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>20.301278</td>\n",
       "      <td>9.338472</td>\n",
       "      <td>28.795669</td>\n",
       "      <td>20.301278</td>\n",
       "      <td>20.301278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.794078</td>\n",
       "      <td>-0.794078</td>\n",
       "      <td>-0.794078</td>\n",
       "      <td>-13.073606</td>\n",
       "      <td>-13.073606</td>\n",
       "      <td>-13.073606</td>\n",
       "      <td>1.179262</td>\n",
       "      <td>1.179262</td>\n",
       "      <td>1.179262</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>1.179262</td>\n",
       "      <td>1.179262</td>\n",
       "      <td>1.179262</td>\n",
       "      <td>2.694787</td>\n",
       "      <td>2.694787</td>\n",
       "      <td>2.694787</td>\n",
       "      <td>-2.910210</td>\n",
       "      <td>-2.910210</td>\n",
       "      <td>-2.910210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.507199</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>20.301390</td>\n",
       "      <td>9.000080</td>\n",
       "      <td>27.480845</td>\n",
       "      <td>20.301390</td>\n",
       "      <td>20.301390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.129173</td>\n",
       "      <td>-2.129173</td>\n",
       "      <td>-2.129173</td>\n",
       "      <td>-14.141622</td>\n",
       "      <td>-14.141622</td>\n",
       "      <td>-14.141622</td>\n",
       "      <td>1.040525</td>\n",
       "      <td>1.040525</td>\n",
       "      <td>1.040525</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>11.315689</td>\n",
       "      <td>1.040525</td>\n",
       "      <td>1.040525</td>\n",
       "      <td>1.040525</td>\n",
       "      <td>2.563614</td>\n",
       "      <td>2.563614</td>\n",
       "      <td>2.563614</td>\n",
       "      <td>-2.907379</td>\n",
       "      <td>-2.907379</td>\n",
       "      <td>-2.907379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.172217</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds      trend  yhat_lower  yhat_upper  trend_lower  \\\n",
       "0 2022-01-01 00:00:00  20.300941    9.988873   28.931039    20.300941   \n",
       "1 2022-01-01 01:00:00  20.301053    9.602739   29.277493    20.301053   \n",
       "2 2022-01-01 02:00:00  20.301166   11.238112   31.089324    20.301166   \n",
       "3 2022-01-01 03:00:00  20.301278    9.338472   28.795669    20.301278   \n",
       "4 2022-01-01 04:00:00  20.301390    9.000080   27.480845    20.301390   \n",
       "\n",
       "   trend_upper  Boxing Day  Boxing Day_lower  Boxing Day_upper  \\\n",
       "0    20.300941         0.0               0.0               0.0   \n",
       "1    20.301053         0.0               0.0               0.0   \n",
       "2    20.301166         0.0               0.0               0.0   \n",
       "3    20.301278         0.0               0.0               0.0   \n",
       "4    20.301390         0.0               0.0               0.0   \n",
       "\n",
       "   Boxing Day (observed)  Boxing Day (observed)_lower  \\\n",
       "0                    0.0                          0.0   \n",
       "1                    0.0                          0.0   \n",
       "2                    0.0                          0.0   \n",
       "3                    0.0                          0.0   \n",
       "4                    0.0                          0.0   \n",
       "\n",
       "   Boxing Day (observed)_upper  Christmas Day  Christmas Day_lower  \\\n",
       "0                          0.0            0.0                  0.0   \n",
       "1                          0.0            0.0                  0.0   \n",
       "2                          0.0            0.0                  0.0   \n",
       "3                          0.0            0.0                  0.0   \n",
       "4                          0.0            0.0                  0.0   \n",
       "\n",
       "   Christmas Day_upper  Christmas Day (observed)  \\\n",
       "0                  0.0                       0.0   \n",
       "1                  0.0                       0.0   \n",
       "2                  0.0                       0.0   \n",
       "3                  0.0                       0.0   \n",
       "4                  0.0                       0.0   \n",
       "\n",
       "   Christmas Day (observed)_lower  Christmas Day (observed)_upper  \\\n",
       "0                             0.0                             0.0   \n",
       "1                             0.0                             0.0   \n",
       "2                             0.0                             0.0   \n",
       "3                             0.0                             0.0   \n",
       "4                             0.0                             0.0   \n",
       "\n",
       "   Good Friday  Good Friday_lower  Good Friday_upper  May Day  May Day_lower  \\\n",
       "0          0.0                0.0                0.0      0.0            0.0   \n",
       "1          0.0                0.0                0.0      0.0            0.0   \n",
       "2          0.0                0.0                0.0      0.0            0.0   \n",
       "3          0.0                0.0                0.0      0.0            0.0   \n",
       "4          0.0                0.0                0.0      0.0            0.0   \n",
       "\n",
       "   May Day_upper  New Year's Day  New Year's Day_lower  New Year's Day_upper  \\\n",
       "0            0.0       11.315689             11.315689             11.315689   \n",
       "1            0.0       11.315689             11.315689             11.315689   \n",
       "2            0.0       11.315689             11.315689             11.315689   \n",
       "3            0.0       11.315689             11.315689             11.315689   \n",
       "4            0.0       11.315689             11.315689             11.315689   \n",
       "\n",
       "   New Year's Day (observed)  New Year's Day (observed)_lower  \\\n",
       "0                        0.0                              0.0   \n",
       "1                        0.0                              0.0   \n",
       "2                        0.0                              0.0   \n",
       "3                        0.0                              0.0   \n",
       "4                        0.0                              0.0   \n",
       "\n",
       "   New Year's Day (observed)_upper  Platinum Jubilee of Elizabeth II  \\\n",
       "0                              0.0                               0.0   \n",
       "1                              0.0                               0.0   \n",
       "2                              0.0                               0.0   \n",
       "3                              0.0                               0.0   \n",
       "4                              0.0                               0.0   \n",
       "\n",
       "   Platinum Jubilee of Elizabeth II_lower  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   Platinum Jubilee of Elizabeth II_upper  Spring Bank Holiday  \\\n",
       "0                                     0.0                  0.0   \n",
       "1                                     0.0                  0.0   \n",
       "2                                     0.0                  0.0   \n",
       "3                                     0.0                  0.0   \n",
       "4                                     0.0                  0.0   \n",
       "\n",
       "   Spring Bank Holiday_lower  Spring Bank Holiday_upper  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   State Funeral of Queen Elizabeth II  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   State Funeral of Queen Elizabeth II_lower  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   State Funeral of Queen Elizabeth II_upper  additive_terms  \\\n",
       "0                                        0.0       -1.114266   \n",
       "1                                        0.0       -0.251013   \n",
       "2                                        0.0        0.476709   \n",
       "3                                        0.0       -0.794078   \n",
       "4                                        0.0       -2.129173   \n",
       "\n",
       "   additive_terms_lower  additive_terms_upper      daily  daily_lower  \\\n",
       "0             -1.114266             -1.114266 -14.096575   -14.096575   \n",
       "1             -0.251013             -0.251013 -13.016521   -13.016521   \n",
       "2              0.476709              0.476709 -12.054215   -12.054215   \n",
       "3             -0.794078             -0.794078 -13.073606   -13.073606   \n",
       "4             -2.129173             -2.129173 -14.141622   -14.141622   \n",
       "\n",
       "   daily_upper  extra_regressors_additive  extra_regressors_additive_lower  \\\n",
       "0   -14.096575                   1.595472                         1.595472   \n",
       "1   -13.016521                   1.456735                         1.456735   \n",
       "2   -12.054215                   1.317998                         1.317998   \n",
       "3   -13.073606                   1.179262                         1.179262   \n",
       "4   -14.141622                   1.040525                         1.040525   \n",
       "\n",
       "   extra_regressors_additive_upper   holidays  holidays_lower  holidays_upper  \\\n",
       "0                         1.595472  11.315689       11.315689       11.315689   \n",
       "1                         1.456735  11.315689       11.315689       11.315689   \n",
       "2                         1.317998  11.315689       11.315689       11.315689   \n",
       "3                         1.179262  11.315689       11.315689       11.315689   \n",
       "4                         1.040525  11.315689       11.315689       11.315689   \n",
       "\n",
       "       hour  hour_lower  hour_upper    weekly  weekly_lower  weekly_upper  \\\n",
       "0  1.595472    1.595472    1.595472  2.989836      2.989836      2.989836   \n",
       "1  1.456735    1.456735    1.456735  2.908948      2.908948      2.908948   \n",
       "2  1.317998    1.317998    1.317998  2.810275      2.810275      2.810275   \n",
       "3  1.179262    1.179262    1.179262  2.694787      2.694787      2.694787   \n",
       "4  1.040525    1.040525    1.040525  2.563614      2.563614      2.563614   \n",
       "\n",
       "     yearly  yearly_lower  yearly_upper  multiplicative_terms  \\\n",
       "0 -2.918688     -2.918688     -2.918688                   0.0   \n",
       "1 -2.915864     -2.915864     -2.915864                   0.0   \n",
       "2 -2.913039     -2.913039     -2.913039                   0.0   \n",
       "3 -2.910210     -2.910210     -2.910210                   0.0   \n",
       "4 -2.907379     -2.907379     -2.907379                   0.0   \n",
       "\n",
       "   multiplicative_terms_lower  multiplicative_terms_upper       yhat  Hour  \n",
       "0                         0.0                         0.0  19.186675     0  \n",
       "1                         0.0                         0.0  20.050040     1  \n",
       "2                         0.0                         0.0  20.777874     2  \n",
       "3                         0.0                         0.0  19.507199     3  \n",
       "4                         0.0                         0.0  18.172217     4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "restaurant_test_fcst_best_r2 = forecast_with_model_r2(m_best_r2, restaurant_test_prophet)\n",
    "display(restaurant_test_fcst_best_r2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 30.106149449114593\n",
      "Peak Hours (Refinement 2): [12, 13, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    peak_hours_dynamic_best_r2,\n",
    "    threshold_best_r2,\n",
    "    tuned_peak_fcst_dynamic_best_r2,\n",
    "    restaurant_test_prophet_peak_dynamic_best_r2,\n",
    "    hourly_avg_best_r2\n",
    ") = select_peak_hours_r2(restaurant_test_fcst_best_r2, restaurant_test_prophet, threshold_ratio=0.6)\n",
    "\n",
    "print(\"Threshold:\", threshold_best_r2)\n",
    "print(\"Peak Hours (Refinement 2):\", peak_hours_dynamic_best_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Model Overall Test Data Metrics (Refinement 2):\n",
      "MAE: 6.094271699414946\n",
      "RMSE: 7.68727213195698\n",
      "MAPE: 1759938633860608.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate error metrics for the tuned model 2 (overall)\n",
    "overall_mae_r2 = mean_absolute_error(restaurant_test['CustomerCount'], restaurant_test_fcst_best_r2['yhat'])\n",
    "overall_rmse_r2 = np.sqrt(mean_squared_error(restaurant_test['CustomerCount'], restaurant_test_fcst_best_r2['yhat']))\n",
    "overall_mape_r2 = mean_absolute_percentage_error(restaurant_test['CustomerCount'], restaurant_test_fcst_best_r2['yhat'])\n",
    "\n",
    "print(\"\\nTuned Model Overall Test Data Metrics (Refinement 2):\")\n",
    "print(\"MAE:\", overall_mae_r2)\n",
    "print(\"RMSE:\", overall_rmse_r2)\n",
    "print(\"MAPE:\", overall_mape_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in restaurant_test:\n",
      "Index(['Year', 'Month', 'Season', 'DayOfWeek', 'WeekDay', 'Hour', 'Holiday',\n",
      "       'Weather', 'SpecialEvent', 'CustomerCount', 'Orders', 'Revenue',\n",
      "       'StaffingLevel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in restaurant_test:\")\n",
    "print(restaurant_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Model Peak Hour Test Data Metrics (Refinement 2):\n",
      "MAE: 7.373625035858816\n",
      "RMSE: 9.181094535180161\n",
      "MAPE: 0.18439167219312655\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Rename 'y' to 'CustomerCount' BEFORE calling the function\n",
    "restaurant_test_prophet_renamed = restaurant_test_prophet.rename(columns={'y': 'CustomerCount'})\n",
    "\n",
    "# Step 2: Now call the function with the renamed DataFrame\n",
    "metrics_r2 = evaluate_metrics_r2(\n",
    "    forecast_df=restaurant_test_fcst_best_r2,\n",
    "    actual_df=restaurant_test_prophet_renamed\n",
    ")\n",
    "\n",
    "# Step 3: Extract and print peak metrics\n",
    "peak_mae_r2 = metrics_r2['peak_hours']['MAE']\n",
    "peak_rmse_r2 = metrics_r2['peak_hours']['RMSE']\n",
    "peak_mape_r2 = metrics_r2['peak_hours']['MAPE']\n",
    "\n",
    "print(\"\\nTuned Model Peak Hour Test Data Metrics (Refinement 2):\")\n",
    "print(\"MAE:\", peak_mae_r2)\n",
    "print(\"RMSE:\", peak_rmse_r2)\n",
    "print(\"MAPE:\", peak_mape_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation (First 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mdape</th>\n",
       "      <th>smape</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36 days 12:00:00</td>\n",
       "      <td>50.438895</td>\n",
       "      <td>7.102035</td>\n",
       "      <td>5.581447</td>\n",
       "      <td>0.312519</td>\n",
       "      <td>0.536020</td>\n",
       "      <td>0.815830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36 days 13:00:00</td>\n",
       "      <td>50.413465</td>\n",
       "      <td>7.100244</td>\n",
       "      <td>5.578501</td>\n",
       "      <td>0.312115</td>\n",
       "      <td>0.535459</td>\n",
       "      <td>0.815830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36 days 14:00:00</td>\n",
       "      <td>50.403893</td>\n",
       "      <td>7.099570</td>\n",
       "      <td>5.578678</td>\n",
       "      <td>0.311743</td>\n",
       "      <td>0.534614</td>\n",
       "      <td>0.815830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36 days 15:00:00</td>\n",
       "      <td>50.481034</td>\n",
       "      <td>7.105001</td>\n",
       "      <td>5.581338</td>\n",
       "      <td>0.311643</td>\n",
       "      <td>0.533751</td>\n",
       "      <td>0.815449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36 days 16:00:00</td>\n",
       "      <td>50.488576</td>\n",
       "      <td>7.105531</td>\n",
       "      <td>5.581773</td>\n",
       "      <td>0.311643</td>\n",
       "      <td>0.533193</td>\n",
       "      <td>0.815449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           horizon        mse      rmse       mae     mdape     smape  \\\n",
       "0 36 days 12:00:00  50.438895  7.102035  5.581447  0.312519  0.536020   \n",
       "1 36 days 13:00:00  50.413465  7.100244  5.578501  0.312115  0.535459   \n",
       "2 36 days 14:00:00  50.403893  7.099570  5.578678  0.311743  0.534614   \n",
       "3 36 days 15:00:00  50.481034  7.105001  5.581338  0.311643  0.533751   \n",
       "4 36 days 16:00:00  50.488576  7.105531  5.581773  0.311643  0.533193   \n",
       "\n",
       "   coverage  \n",
       "0  0.815830  \n",
       "1  0.815830  \n",
       "2  0.815830  \n",
       "3  0.815449  \n",
       "4  0.815449  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cv_r2, df_p_r2 = cross_validate_model_r2(m_best_r2)\n",
    "\n",
    "print(\"Cross-Validation (First 5 rows):\")\n",
    "display(df_p_r2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Summary (Refinement 2):\n",
      "RMSE: 7.471\n",
      "MAE: 5.936\n",
      "SMAPE: 0.485\n"
     ]
    }
   ],
   "source": [
    "#Cross-Validation Summary for overall\n",
    "print(\"\\nCross-Validation Summary (Refinement 2):\")\n",
    "for metric in ['rmse', 'mae', 'mape', 'smape']:\n",
    "    if metric in df_p_r2.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r2[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Performance Metrics (Average) for Peak Hours Only - Refinement 2:\n",
      "RMSE: 9.071\n",
      "MAE: 7.235\n",
      "MAPE: 0.190\n",
      "SMAPE: 0.183\n"
     ]
    }
   ],
   "source": [
    "# --- Peak Hours CV Metrics for Refinement 2 ---\n",
    "\n",
    "df_cv_r2['hour'] = df_cv_r2['ds'].dt.hour\n",
    "df_cv_r2_peak = df_cv_r2[df_cv_r2['hour'].isin(peak_hours_dynamic_best_r2)]\n",
    "\n",
    "df_p_r2_peak = performance_metrics(df_cv_r2_peak)\n",
    "\n",
    "# Display average metrics for peak hour performance\n",
    "print(\"\\nCross-Validation Performance Metrics (Average) for Peak Hours Only - Refinement 2:\")\n",
    "for metric in ['rmse', 'mae', 'mape', 'smape']:\n",
    "    if metric in df_p_r2_peak.columns:\n",
    "        print(f\"{metric.upper()}: {df_p_r2_peak[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30-day future forecast using Refinement 2 model\n",
    "forecast_future_r2, future_hourly_avg_r2, threshold_r2, future_peak_hours_r2 = forecast_future_with_model_r2(\n",
    "    m_best_r2, days=30, freq='H', threshold_ratio=0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
