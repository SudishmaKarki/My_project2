{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Working directory: /Users/sudishmakarki/My_project2\n"
     ]
    }
   ],
   "source": [
    "# Set working directory (optional during development)\n",
    "import os\n",
    "os.chdir('/Users/sudishmakarki/My_project2')  # only if needed\n",
    "print(\" Working directory:\", os.getcwd())\n",
    "\n",
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Custom Functions\n",
    "from models.data_interpolation import (\n",
    "    load_data,\n",
    "    preprocess_data,\n",
    "    split_train_test,\n",
    "    generate_time_series_splits\n",
    ")\n",
    "\n",
    "from models.model_sarimax import (\n",
    "    prepare_sarimax_data,\n",
    "    check_stationarity,\n",
    "    plot_acf_pacf,\n",
    "    fit_sarimax_model,\n",
    "    analyze_residual_spike,\n",
    "    ljung_box_test,\n",
    "    forecast_sarimax_model,\n",
    "    identify_peak_hours_sarimax,\n",
    "    evaluate_sarimax_metrics,\n",
    "    rolling_forecast_sarimax,\n",
    "    generate_future_forecast_sarimax,\n",
    "    group_forecast_by_hour,\n",
    "    \n",
    ")\n",
    "\n",
    "from models.model_sarimax import (\n",
    "    create_exogenous_variables,\n",
    "    fit_sarimax_with_exog,\n",
    "    ljung_box_test_refined_sarimax,\n",
    "    analyze_largest_residual_sarimax_exog,\n",
    "    forecast_with_exog,\n",
    "    analyze_peak_hours_exog,\n",
    "    evaluate_sarimax_exog_metrics,\n",
    "    rolling_forecast_sarimax_exog,\n",
    "    generate_future_forecast_sarimax_exog,\n",
    "    group_forecast_by_hour_sarimax_exog\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Functions\n",
    "from models.data_interpolation import (\n",
    "    load_data,\n",
    "    preprocess_data,\n",
    "    split_train_test,\n",
    "    generate_time_series_splits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Year  Month  Season  DayOfWeek WeekDay  Hour  \\\n",
      "Timestamp                                                           \n",
      "2018-01-01 00:00:00  2018      1  Winter          1  Monday     0   \n",
      "2018-01-01 01:00:00  2018      1  Winter          1  Monday     1   \n",
      "2018-01-01 02:00:00  2018      1  Winter          1  Monday     2   \n",
      "2018-01-01 03:00:00  2018      1  Winter          1  Monday     3   \n",
      "2018-01-01 04:00:00  2018      1  Winter          1  Monday     4   \n",
      "\n",
      "                            Holiday Weather SpecialEvent  CustomerCount  \\\n",
      "Timestamp                                                                 \n",
      "2018-01-01 00:00:00  New Year's Day   Rainy          NaN              6   \n",
      "2018-01-01 01:00:00  New Year's Day   Windy          NaN             11   \n",
      "2018-01-01 02:00:00  New Year's Day   Snowy          NaN              9   \n",
      "2018-01-01 03:00:00  New Year's Day   Rainy          NaN             10   \n",
      "2018-01-01 04:00:00  New Year's Day  Cloudy          NaN             14   \n",
      "\n",
      "                     Orders  Revenue  StaffingLevel  \n",
      "Timestamp                                            \n",
      "2018-01-01 00:00:00       5    52.30              5  \n",
      "2018-01-01 01:00:00       7   129.41              7  \n",
      "2018-01-01 02:00:00       6    94.64              5  \n",
      "2018-01-01 03:00:00       5    80.61              7  \n",
      "2018-01-01 04:00:00      11   184.34              5  \n",
      " \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 43824 entries, 2018-01-01 00:00:00 to 2022-12-31 23:00:00\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Year           43824 non-null  int64  \n",
      " 1   Month          43824 non-null  int64  \n",
      " 2   Season         43824 non-null  object \n",
      " 3   DayOfWeek      43824 non-null  int64  \n",
      " 4   WeekDay        43824 non-null  object \n",
      " 5   Hour           43824 non-null  int64  \n",
      " 6   Holiday        43824 non-null  object \n",
      " 7   Weather        43824 non-null  object \n",
      " 8   SpecialEvent   120 non-null    object \n",
      " 9   CustomerCount  43824 non-null  int64  \n",
      " 10  Orders         43824 non-null  int64  \n",
      " 11  Revenue        43824 non-null  float64\n",
      " 12  StaffingLevel  43824 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(5)\n",
      "memory usage: 4.7+ MB\n",
      "None\n",
      "Missing data in each column:\n",
      "Year             False\n",
      "Month            False\n",
      "Season           False\n",
      "DayOfWeek        False\n",
      "WeekDay          False\n",
      "Hour             False\n",
      "Holiday          False\n",
      "Weather          False\n",
      "SpecialEvent      True\n",
      "CustomerCount    False\n",
      "Orders           False\n",
      "Revenue          False\n",
      "StaffingLevel    False\n",
      "dtype: bool\n",
      " \n",
      "\n",
      "Summary Statistics:\n",
      "               Year         Month     DayOfWeek          Hour  CustomerCount  \\\n",
      "count  43824.000000  43824.000000  43824.000000  43824.000000   43824.000000   \n",
      "mean    2020.000000      6.523549      3.998357     11.500000      19.081029   \n",
      "std        1.413842      3.448572      1.999337      6.922266      15.447294   \n",
      "min     2018.000000      1.000000      1.000000      0.000000       0.000000   \n",
      "25%     2019.000000      4.000000      2.000000      5.750000       7.000000   \n",
      "50%     2020.000000      7.000000      4.000000     11.500000      14.000000   \n",
      "75%     2021.000000     10.000000      6.000000     17.250000      31.000000   \n",
      "max     2022.000000     12.000000      7.000000     23.000000      77.000000   \n",
      "\n",
      "             Orders       Revenue  StaffingLevel  \n",
      "count  43824.000000  43824.000000   43824.000000  \n",
      "mean      13.445692    202.368099       5.928852  \n",
      "std       10.886505    163.660999       1.579194  \n",
      "min        0.000000      0.000000       3.000000  \n",
      "25%        5.000000     70.710000       5.000000  \n",
      "50%       10.000000    154.580000       6.000000  \n",
      "75%       22.000000    326.020000       7.000000  \n",
      "max       55.000000    850.630000      12.000000  \n",
      "Season\n",
      "Spring    11040\n",
      "Summer    11040\n",
      "Fall      10920\n",
      "Winter    10824\n",
      "Name: count, dtype: int64\n",
      "2018-01-01    24\n",
      "2018-01-02    24\n",
      "2018-01-03    24\n",
      "2018-01-04    24\n",
      "2018-01-05    24\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess\n",
    "df = load_data('data/RestaurantData.csv')\n",
    "df_clean = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "restaurant_train, restaurant_test = split_train_test(df_clean, split_date='2022-01-01')\n",
    "# Format for SARIMAX\n",
    "train_series, test_series = prepare_sarimax_data(restaurant_train, restaurant_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMAX Exogenous Variables model refinement 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the datetime index is correctly set and frequency is hourly\n",
    "restaurant_subset_train = restaurant_train.copy()\n",
    "restaurant_subset_test = restaurant_test.copy()\n",
    "\n",
    "restaurant_subset_train.index = pd.to_datetime(restaurant_subset_train.index)\n",
    "restaurant_subset_train = restaurant_subset_train.asfreq('h')\n",
    "\n",
    "restaurant_subset_test.index = pd.to_datetime(restaurant_subset_test.index)\n",
    "restaurant_subset_test = restaurant_subset_test.asfreq('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>Holiday_Boxing Day</th>\n",
       "      <th>Holiday_Boxing Day (observed)</th>\n",
       "      <th>Holiday_Christmas Day</th>\n",
       "      <th>Holiday_Christmas Day (observed)</th>\n",
       "      <th>Holiday_Good Friday</th>\n",
       "      <th>Holiday_May Day</th>\n",
       "      <th>Holiday_New Year's Day</th>\n",
       "      <th>Holiday_New Year's Day (observed)</th>\n",
       "      <th>Holiday_No Holiday</th>\n",
       "      <th>Holiday_Platinum Jubilee of Elizabeth II</th>\n",
       "      <th>Holiday_Spring Bank Holiday</th>\n",
       "      <th>Holiday_State Funeral of Queen Elizabeth II</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  Holiday_Boxing Day  Holiday_Boxing Day (observed)  \\\n",
       "Timestamp                                                                      \n",
       "2018-01-01 00:00:00     0                 0.0                            0.0   \n",
       "2018-01-01 01:00:00     1                 0.0                            0.0   \n",
       "2018-01-01 02:00:00     2                 0.0                            0.0   \n",
       "2018-01-01 03:00:00     3                 0.0                            0.0   \n",
       "2018-01-01 04:00:00     4                 0.0                            0.0   \n",
       "\n",
       "                     Holiday_Christmas Day  Holiday_Christmas Day (observed)  \\\n",
       "Timestamp                                                                      \n",
       "2018-01-01 00:00:00                    0.0                               0.0   \n",
       "2018-01-01 01:00:00                    0.0                               0.0   \n",
       "2018-01-01 02:00:00                    0.0                               0.0   \n",
       "2018-01-01 03:00:00                    0.0                               0.0   \n",
       "2018-01-01 04:00:00                    0.0                               0.0   \n",
       "\n",
       "                     Holiday_Good Friday  Holiday_May Day  \\\n",
       "Timestamp                                                   \n",
       "2018-01-01 00:00:00                  0.0              0.0   \n",
       "2018-01-01 01:00:00                  0.0              0.0   \n",
       "2018-01-01 02:00:00                  0.0              0.0   \n",
       "2018-01-01 03:00:00                  0.0              0.0   \n",
       "2018-01-01 04:00:00                  0.0              0.0   \n",
       "\n",
       "                     Holiday_New Year's Day  \\\n",
       "Timestamp                                     \n",
       "2018-01-01 00:00:00                     1.0   \n",
       "2018-01-01 01:00:00                     1.0   \n",
       "2018-01-01 02:00:00                     1.0   \n",
       "2018-01-01 03:00:00                     1.0   \n",
       "2018-01-01 04:00:00                     1.0   \n",
       "\n",
       "                     Holiday_New Year's Day (observed)  Holiday_No Holiday  \\\n",
       "Timestamp                                                                    \n",
       "2018-01-01 00:00:00                                0.0                 0.0   \n",
       "2018-01-01 01:00:00                                0.0                 0.0   \n",
       "2018-01-01 02:00:00                                0.0                 0.0   \n",
       "2018-01-01 03:00:00                                0.0                 0.0   \n",
       "2018-01-01 04:00:00                                0.0                 0.0   \n",
       "\n",
       "                     Holiday_Platinum Jubilee of Elizabeth II  \\\n",
       "Timestamp                                                       \n",
       "2018-01-01 00:00:00                                       0.0   \n",
       "2018-01-01 01:00:00                                       0.0   \n",
       "2018-01-01 02:00:00                                       0.0   \n",
       "2018-01-01 03:00:00                                       0.0   \n",
       "2018-01-01 04:00:00                                       0.0   \n",
       "\n",
       "                     Holiday_Spring Bank Holiday  \\\n",
       "Timestamp                                          \n",
       "2018-01-01 00:00:00                          0.0   \n",
       "2018-01-01 01:00:00                          0.0   \n",
       "2018-01-01 02:00:00                          0.0   \n",
       "2018-01-01 03:00:00                          0.0   \n",
       "2018-01-01 04:00:00                          0.0   \n",
       "\n",
       "                     Holiday_State Funeral of Queen Elizabeth II  \n",
       "Timestamp                                                         \n",
       "2018-01-01 00:00:00                                          0.0  \n",
       "2018-01-01 01:00:00                                          0.0  \n",
       "2018-01-01 02:00:00                                          0.0  \n",
       "2018-01-01 03:00:00                                          0.0  \n",
       "2018-01-01 04:00:00                                          0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract exogenous variables (hour + holidays) for train and test\n",
    "exog_train, exog_test = create_exogenous_variables(restaurant_subset_train, restaurant_subset_test)\n",
    "exog_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- Quick Test Mode: SARIMAX with Exogenous Variables (Small Subset) ---\\n\\n# Slice last 2000 rows for fast testing\\nsmall_train_series = train_series.iloc[-2000:]\\nsmall_exog_train = exog_train.iloc[-2000:]\\n\\n# Define SARIMAX parameters\\norder = (1, 1, 1)\\nseasonal_order = (1, 1, 1, 24)\\n\\n# Fit model on small subset\\nresults_exog_test = fit_sarimax_with_exog(\\n    small_train_series,\\n    small_exog_train,\\n    order=order,\\n    seasonal_order=seasonal_order\\n)\\n\\n# Forecast 24 steps ahead using test exogenous features\\nexog_forecast_input = exog_test.iloc[:24]\\nforecast_test, forecast_ci_test = forecast_with_exog(results_exog_test, exog_forecast_input, exog_forecast_input.index)\\n\\n# Preview forecast\\nforecast_test.head()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# --- Quick Test Mode: SARIMAX with Exogenous Variables (Small Subset) ---\n",
    "\n",
    "# Slice last 2000 rows for fast testing\n",
    "small_train_series = train_series.iloc[-2000:]\n",
    "small_exog_train = exog_train.iloc[-2000:]\n",
    "\n",
    "# Define SARIMAX parameters\n",
    "order = (1, 1, 1)\n",
    "seasonal_order = (1, 1, 1, 24)\n",
    "\n",
    "# Fit model on small subset\n",
    "results_exog_test = fit_sarimax_with_exog(\n",
    "    small_train_series,\n",
    "    small_exog_train,\n",
    "    order=order,\n",
    "    seasonal_order=seasonal_order\n",
    ")\n",
    "\n",
    "# Forecast 24 steps ahead using test exogenous features\n",
    "exog_forecast_input = exog_test.iloc[:24]\n",
    "forecast_test, forecast_ci_test = forecast_with_exog(results_exog_test, exog_forecast_input, exog_forecast_input.index)\n",
    "\n",
    "# Preview forecast\n",
    "forecast_test.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SARIMAX model with exogenous variables\n",
    "order = (1, 1, 1)\n",
    "seasonal_order = (1, 1, 1, 24)\n",
    "\n",
    "results_exog_full = fit_sarimax_with_exog(train_series, exog_train, order=order, seasonal_order=seasonal_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals from the exogenous model\n",
    "residuals_exog = results_exog_full.resid\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(residuals_exog)\n",
    "plt.title(\"Residuals Over Time (Exogenous Model)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plot_acf(residuals_exog.dropna(), lags=40)\n",
    "plt.title(\"ACF of Residuals\")\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(residuals_exog.dropna(), lags=40)\n",
    "plt.title(\"PACF of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Largest Residual Check\n",
    "analyze_largest_residual_sarimax_exog(residuals_exog, restaurant_subset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ljung-Box Test\n",
    "ljung_box_test_refined_sarimax(residuals_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting on the Test Set with Exogenous Variables\n",
    "forecast_mean_exog, forecast_ci_exog = forecast_with_exog(\n",
    "    results_exog_full,\n",
    "    exog_test=exog_test,\n",
    "    test_index=restaurant_subset_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Forecast vs Actual\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_series.index, train_series, label='Training Data', color='steelblue')\n",
    "plt.plot(test_series.index, test_series, label='Actual Test Data', color='blue')\n",
    "plt.plot(forecast_mean_exog.index, forecast_mean_exog, label='Forecast', color='red')\n",
    "plt.fill_between(forecast_ci_exog.index,\n",
    "                 forecast_ci_exog.iloc[:, 0],\n",
    "                 forecast_ci_exog.iloc[:, 1],\n",
    "                 color='pink', alpha=0.3, label='Confidence Interval')\n",
    "plt.title(\"SARIMAX (Exogenous) Forecast vs Actual\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"CustomerCount\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_mean_exog_full, forecast_ci_exog_full = forecast_with_exog(\n",
    "    results_exog_full,\n",
    "    exog_test=exog_test,\n",
    "    test_index=test_series.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Zoomed-In Plot for January 2022 ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training, actual test, and forecast\n",
    "plt.plot(restaurant_subset_train.index, train_series, label='Training Data', color='steelblue')\n",
    "plt.plot(restaurant_subset_test.index, test_series, label='Actual Test Data', color='blue')\n",
    "plt.plot(forecast_mean_exog_full.index, forecast_mean_exog_full, label='Forecast', color='red')\n",
    "\n",
    "# Confidence interval shading\n",
    "plt.fill_between(forecast_ci_exog_full.index,\n",
    "                 forecast_ci_exog_full.iloc[:, 0],\n",
    "                 forecast_ci_exog_full.iloc[:, 1],\n",
    "                 color='pink', alpha=0.3, label='Confidence Interval')\n",
    "\n",
    "# Zoomed-in x-axis range (January 2022)\n",
    "plt.xlim(pd.to_datetime(\"2022-01-01\"), pd.to_datetime(\"2022-01-31\"))\n",
    "\n",
    "# Labels and legend\n",
    "plt.title(\"ðŸ“ˆ SARIMAX Forecast vs Actual (Zoomed-In: January 2022)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"CustomerCount\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify Peak Hours\n",
    "peak_hours_exog, threshold_exog, hourly_avg_exog, forecast_peak_exog, test_peak_exog = analyze_peak_hours_exog(\n",
    "    forecast_mean_exog, test_series, threshold_ratio=0.6\n",
    ")\n",
    "\n",
    "# Optional: display hourly average\n",
    "display(\n",
    "    hourly_avg_exog.reset_index(name='Avg Forecast (yhat)')\n",
    "    .style.set_caption(\"SARIMAX Exog: Hourly Avg Forecast\")\n",
    "    .background_gradient(cmap='Blues', subset=['Avg Forecast (yhat)'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Metrics\n",
    "display(evaluate_sarimax_exog_metrics(\n",
    "    test_series, forecast_mean_exog, test_peak_exog, forecast_peak_exog\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling Forecast with Exogenous Inputs\n",
    "rolling_overall_metrics_exog, rolling_peak_metrics_exog, _, _, _, _ = rolling_forecast_sarimax_exog(\n",
    "    train_series=train_series,\n",
    "    test_series=test_series,\n",
    "    exog_train=exog_train,\n",
    "    exog_test=exog_test,\n",
    "    best_order=order,\n",
    "    best_seasonal_order=seasonal_order,\n",
    "    peak_hours=peak_hours_exog\n",
    ")\n",
    "\n",
    "# Format and display\n",
    "rolling_metrics_df = pd.DataFrame([\n",
    "    [\"MAE\", \"Overall\", rolling_overall_metrics_exog['MAE']],\n",
    "    [\"RMSE\", \"Overall\", rolling_overall_metrics_exog['RMSE']],\n",
    "    [\"MAPE\", \"Overall\", rolling_overall_metrics_exog['MAPE']],\n",
    "    [\"MAE\", \"Peak Hours\", rolling_peak_metrics_exog['MAE']],\n",
    "    [\"RMSE\", \"Peak Hours\", rolling_peak_metrics_exog['RMSE']],\n",
    "    [\"MAPE\", \"Peak Hours\", rolling_peak_metrics_exog['MAPE']],\n",
    "], columns=[\"Metric\", \"Type\", \"Value\"])\n",
    "\n",
    "display(rolling_metrics_df.style.set_caption(\"Rolling Forecast Metrics (Exogenous SARIMAX)\").background_gradient(cmap='Blues', subset=[\"Value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Future Forecast (30 Days)\n",
    "forecast_future_exog = generate_future_forecast_sarimax_exog(results_exog_full)\n",
    "\n",
    "# Optional: Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(forecast_future_exog['ds'], forecast_future_exog['yhat'], label='Forecast')\n",
    "plt.title(\"30-Day Future Forecast (SARIMAX with Exogenous)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Forecasted CustomerCount\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group Forecast by Hour\n",
    "future_hourly_df_exog, threshold_future_exog, future_peak_hours_exog = group_forecast_by_hour_sarimax_exog(\n",
    "    forecast_future_exog, threshold_ratio=0.6\n",
    ")\n",
    "\n",
    "# Display as styled table\n",
    "display(future_hourly_df_exog.style.set_caption(\"Future Hourly Avg Forecast (Exog)\").background_gradient(cmap='Blues'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
