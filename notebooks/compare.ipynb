{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Working directory: /Users/sudishmakarki/My_project2\n"
     ]
    }
   ],
   "source": [
    "# Set working directory (optional during development)\n",
    "import pickle\n",
    "import os\n",
    "os.chdir('/Users/sudishmakarki/My_project2')  # only if needed\n",
    "print(\" Working directory:\", os.getcwd())\n",
    "\n",
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Custom Functions\n",
    "from models.data_interpolation import (\n",
    "    load_data,\n",
    "    preprocess_data,\n",
    "    split_train_test,\n",
    "    generate_time_series_splits\n",
    ")\n",
    "\n",
    "from models.model_prophet import (\n",
    "    prepare_prophet_data,\n",
    "    calculate_peak_hours,\n",
    "    train_baseline_prophet,\n",
    "    prepare_holiday_df,\n",
    "    evaluate_metrics,\n",
    "    select_peak_hours,\n",
    "    tune_prophet_model,\n",
    "    evaluate_tuned_model_metrics,\n",
    "    forecast_with_model_r1,\n",
    "    forecast_with_model_r2,\n",
    "    forecast_future_with_model_r1,\n",
    "    tune_prophet_model_r2,\n",
    "    select_peak_hours_r2,\n",
    "    evaluate_metrics_r2,\n",
    "    forecast_future_with_model_r2\n",
    ")\n",
    "\n",
    "from models.model_sarimax import (\n",
    "    prepare_sarimax_data,\n",
    "    fit_sarimax_model,\n",
    "    sarimax_grid_search,\n",
    "    retrain_sarimax_model,\n",
    "    create_exogenous_variables,\n",
    "    fit_sarimax_with_exog,\n",
    "    evaluate_sarimax_metrics,            # SARIMAX Baseline\n",
    "    evaluate_refined_sarimax_metrics,    # SARIMAX R1\n",
    "    evaluate_sarimax_exog_metrics,       # SARIMAX R2 (exog)\n",
    "    generate_future_forecast_sarimax,    # Future forecast (baseline and R1)\n",
    "    forecast_future_sarimax_model_refined,  # Future forecast (R1)\n",
    "    generate_future_forecast_sarimax_exog,  # Future forecast (R2)\n",
    "    group_forecast_by_hour,              # Peak hour grouping (baseline/R1)\n",
    "    group_forecast_by_hour_sarimax_exog  # Peak hour grouping (R2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Year  Month  Season  DayOfWeek WeekDay  Hour  \\\n",
      "Timestamp                                                           \n",
      "2018-01-01 00:00:00  2018      1  Winter          1  Monday     0   \n",
      "2018-01-01 01:00:00  2018      1  Winter          1  Monday     1   \n",
      "2018-01-01 02:00:00  2018      1  Winter          1  Monday     2   \n",
      "2018-01-01 03:00:00  2018      1  Winter          1  Monday     3   \n",
      "2018-01-01 04:00:00  2018      1  Winter          1  Monday     4   \n",
      "\n",
      "                            Holiday Weather SpecialEvent  CustomerCount  \\\n",
      "Timestamp                                                                 \n",
      "2018-01-01 00:00:00  New Year's Day   Rainy          NaN              6   \n",
      "2018-01-01 01:00:00  New Year's Day   Windy          NaN             11   \n",
      "2018-01-01 02:00:00  New Year's Day   Snowy          NaN              9   \n",
      "2018-01-01 03:00:00  New Year's Day   Rainy          NaN             10   \n",
      "2018-01-01 04:00:00  New Year's Day  Cloudy          NaN             14   \n",
      "\n",
      "                     Orders  Revenue  StaffingLevel  \n",
      "Timestamp                                            \n",
      "2018-01-01 00:00:00       5    52.30              5  \n",
      "2018-01-01 01:00:00       7   129.41              7  \n",
      "2018-01-01 02:00:00       6    94.64              5  \n",
      "2018-01-01 03:00:00       5    80.61              7  \n",
      "2018-01-01 04:00:00      11   184.34              5  \n",
      " \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 43824 entries, 2018-01-01 00:00:00 to 2022-12-31 23:00:00\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Year           43824 non-null  int64  \n",
      " 1   Month          43824 non-null  int64  \n",
      " 2   Season         43824 non-null  object \n",
      " 3   DayOfWeek      43824 non-null  int64  \n",
      " 4   WeekDay        43824 non-null  object \n",
      " 5   Hour           43824 non-null  int64  \n",
      " 6   Holiday        43824 non-null  object \n",
      " 7   Weather        43824 non-null  object \n",
      " 8   SpecialEvent   120 non-null    object \n",
      " 9   CustomerCount  43824 non-null  int64  \n",
      " 10  Orders         43824 non-null  int64  \n",
      " 11  Revenue        43824 non-null  float64\n",
      " 12  StaffingLevel  43824 non-null  int64  \n",
      "dtypes: float64(1), int64(7), object(5)\n",
      "memory usage: 4.7+ MB\n",
      "None\n",
      "Missing data in each column:\n",
      "Year             False\n",
      "Month            False\n",
      "Season           False\n",
      "DayOfWeek        False\n",
      "WeekDay          False\n",
      "Hour             False\n",
      "Holiday          False\n",
      "Weather          False\n",
      "SpecialEvent      True\n",
      "CustomerCount    False\n",
      "Orders           False\n",
      "Revenue          False\n",
      "StaffingLevel    False\n",
      "dtype: bool\n",
      " \n",
      "\n",
      "Summary Statistics:\n",
      "               Year         Month     DayOfWeek          Hour  CustomerCount  \\\n",
      "count  43824.000000  43824.000000  43824.000000  43824.000000   43824.000000   \n",
      "mean    2020.000000      6.523549      3.998357     11.500000      19.081029   \n",
      "std        1.413842      3.448572      1.999337      6.922266      15.447294   \n",
      "min     2018.000000      1.000000      1.000000      0.000000       0.000000   \n",
      "25%     2019.000000      4.000000      2.000000      5.750000       7.000000   \n",
      "50%     2020.000000      7.000000      4.000000     11.500000      14.000000   \n",
      "75%     2021.000000     10.000000      6.000000     17.250000      31.000000   \n",
      "max     2022.000000     12.000000      7.000000     23.000000      77.000000   \n",
      "\n",
      "             Orders       Revenue  StaffingLevel  \n",
      "count  43824.000000  43824.000000   43824.000000  \n",
      "mean      13.445692    202.368099       5.928852  \n",
      "std       10.886505    163.660999       1.579194  \n",
      "min        0.000000      0.000000       3.000000  \n",
      "25%        5.000000     70.710000       5.000000  \n",
      "50%       10.000000    154.580000       6.000000  \n",
      "75%       22.000000    326.020000       7.000000  \n",
      "max       55.000000    850.630000      12.000000  \n",
      "Season\n",
      "Spring    11040\n",
      "Summer    11040\n",
      "Fall      10920\n",
      "Winter    10824\n",
      "Name: count, dtype: int64\n",
      "2018-01-01    24\n",
      "2018-01-02    24\n",
      "2018-01-03    24\n",
      "2018-01-04    24\n",
      "2018-01-05    24\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess\n",
    "df = load_data('data/RestaurantData.csv')\n",
    "df_clean = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/prophet_baseline.pkl\", \"rb\") as f:\n",
    "    loaded_baseline = pickle.load(f)\n",
    "\n",
    "with open(\"models/prophet_r1.pkl\", \"rb\") as f:\n",
    "    loaded_r1 = pickle.load(f)\n",
    "\n",
    "with open(\"models/prophet_r2.pkl\", \"rb\") as f:\n",
    "    loaded_r2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "restaurant_train, restaurant_test = split_train_test(df_clean, split_date='2022-01-01')\n",
    "# Format for Prophet\n",
    "restaurant_train_prophet, restaurant_test_prophet = prepare_prophet_data(restaurant_train, restaurant_test)\n",
    "# Format for SARIMAX\n",
    "train_series, test_series = prepare_sarimax_data(restaurant_train, restaurant_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the test set (just like before)\n",
    "restaurant_test_prophet = restaurant_test.reset_index().rename(columns={'Timestamp': 'ds', 'CustomerCount': 'y'})\n",
    "restaurant_test_prophet['hour'] = restaurant_test_prophet['ds'].dt.hour\n",
    "\n",
    "# For metric functions that expect CustomerCount\n",
    "restaurant_test_prophet['CustomerCount'] = restaurant_test_prophet['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasts\n",
    "fcst_baseline = loaded_baseline.predict(restaurant_test_prophet)\n",
    "fcst_baseline['Hour'] = fcst_baseline['ds'].dt.hour\n",
    "\n",
    "fcst_r1 = loaded_r1.predict(restaurant_test_prophet)\n",
    "fcst_r1['Hour'] = fcst_r1['ds'].dt.hour\n",
    "\n",
    "fcst_r2 = loaded_r2.predict(restaurant_test_prophet)\n",
    "fcst_r2['Hour'] = fcst_r2['ds'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecast using the loaded R1 model\n",
    "fcst_r1 = loaded_r1.predict(restaurant_test_prophet)\n",
    "fcst_r1['Hour'] = fcst_r1['ds'].dt.hour  # needed for peak hour analysisr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from the baseline model (already loaded from pickle as loaded_baseline)\n",
    "fcst_baseline = loaded_baseline.predict(restaurant_test_prophet)\n",
    "fcst_baseline['Hour'] = fcst_baseline['ds'].dt.hour\n",
    "\n",
    "# Identify peak hours\n",
    "peak_hours_baseline, _, _ = calculate_peak_hours(fcst_baseline)\n",
    "\n",
    "# Evaluate baseline metrics\n",
    "metrics_baseline = evaluate_metrics(\n",
    "    restaurant_test_prophet,  # actuals with 'y'\n",
    "    fcst_baseline,\n",
    "    peak_hours_baseline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Model Overall Test Data Metrics:\n",
      "MAE: 6.1804818847201055\n",
      "RMSE: 7.787756838129002\n",
      "MAPE: 1799928417792683.2\n",
      "\n",
      "Tuned Model Peak Hours Metrics:\n",
      "MAE: 7.4295155584022385\n",
      "RMSE: 9.25714616325585\n",
      "MAPE: 0.18551151193478085\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate fresh forecast from loaded model\n",
    "fcst_r1 = loaded_r1.predict(restaurant_test_prophet)\n",
    "fcst_r1['Hour'] = fcst_r1['ds'].dt.hour\n",
    "\n",
    "# 2. Select peak hours and get peak subsets\n",
    "peak_hours_r1, _, fcst_peak_r1, test_peak_r1, _ = select_peak_hours(fcst_r1, restaurant_test_prophet)\n",
    "\n",
    "# 3. Evaluate metrics\n",
    "metrics_r1 = evaluate_tuned_model_metrics(\n",
    "    restaurant_test,       # actuals with CustomerCount\n",
    "    fcst_r1,               # full forecast with 'yhat'\n",
    "    test_peak_r1,          # actuals for peak\n",
    "    fcst_peak_r1           # forecast for peak (must have yhat!)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall': {'MAE': 6.094271699414946, 'RMSE': np.float64(7.68727213195698), 'MAPE': 1759938633860608.5}, 'peak_hours': {'MAE': 7.373625035858816, 'RMSE': np.float64(9.181094535180161), 'MAPE': 0.18439167219312655}}\n"
     ]
    }
   ],
   "source": [
    "# Ensure proper column for comparison\n",
    "actual_customer_counts = restaurant_test_prophet['y']\n",
    "\n",
    "# Then evaluate metrics\n",
    "metrics_r2 = evaluate_metrics_r2(\n",
    "    forecast_df=fcst_r2,                            # must have 'yhat'\n",
    "    actual_df=pd.DataFrame({\n",
    "        \"ds\": restaurant_test_prophet['ds'],\n",
    "        \"CustomerCount\": actual_customer_counts     # single actual column\n",
    "    }),\n",
    "    customer_col=\"CustomerCount\"\n",
    ")\n",
    "\n",
    "print(metrics_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b5ea1_row0_col2, #T_b5ea1_row0_col3, #T_b5ea1_row0_col4, #T_b5ea1_row1_col2, #T_b5ea1_row1_col3, #T_b5ea1_row1_col4, #T_b5ea1_row3_col2, #T_b5ea1_row3_col3, #T_b5ea1_row3_col4, #T_b5ea1_row4_col2, #T_b5ea1_row4_col3, #T_b5ea1_row4_col4, #T_b5ea1_row5_col2, #T_b5ea1_row5_col3, #T_b5ea1_row5_col4 {\n",
       "  background-color: #ffffd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b5ea1_row2_col2, #T_b5ea1_row2_col3, #T_b5ea1_row2_col4 {\n",
       "  background-color: #081d58;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b5ea1\">\n",
       "  <caption>📊 Prophet Model Comparison (Baseline vs R1 vs R2)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5ea1_level0_col0\" class=\"col_heading level0 col0\" >Metric</th>\n",
       "      <th id=\"T_b5ea1_level0_col1\" class=\"col_heading level0 col1\" >Type</th>\n",
       "      <th id=\"T_b5ea1_level0_col2\" class=\"col_heading level0 col2\" >Prophet Baseline</th>\n",
       "      <th id=\"T_b5ea1_level0_col3\" class=\"col_heading level0 col3\" >Prophet R1</th>\n",
       "      <th id=\"T_b5ea1_level0_col4\" class=\"col_heading level0 col4\" >Prophet R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b5ea1_row0_col0\" class=\"data row0 col0\" >MAE</td>\n",
       "      <td id=\"T_b5ea1_row0_col1\" class=\"data row0 col1\" >Overall</td>\n",
       "      <td id=\"T_b5ea1_row0_col2\" class=\"data row0 col2\" >6.178833</td>\n",
       "      <td id=\"T_b5ea1_row0_col3\" class=\"data row0 col3\" >6.180482</td>\n",
       "      <td id=\"T_b5ea1_row0_col4\" class=\"data row0 col4\" >6.094272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b5ea1_row1_col0\" class=\"data row1 col0\" >RMSE</td>\n",
       "      <td id=\"T_b5ea1_row1_col1\" class=\"data row1 col1\" >Overall</td>\n",
       "      <td id=\"T_b5ea1_row1_col2\" class=\"data row1 col2\" >7.792611</td>\n",
       "      <td id=\"T_b5ea1_row1_col3\" class=\"data row1 col3\" >7.787757</td>\n",
       "      <td id=\"T_b5ea1_row1_col4\" class=\"data row1 col4\" >7.687272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b5ea1_row2_col0\" class=\"data row2 col0\" >MAPE</td>\n",
       "      <td id=\"T_b5ea1_row2_col1\" class=\"data row2 col1\" >Overall</td>\n",
       "      <td id=\"T_b5ea1_row2_col2\" class=\"data row2 col2\" >1750259904361487.000000</td>\n",
       "      <td id=\"T_b5ea1_row2_col3\" class=\"data row2 col3\" >1799928417792683.250000</td>\n",
       "      <td id=\"T_b5ea1_row2_col4\" class=\"data row2 col4\" >1759938633860608.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b5ea1_row3_col0\" class=\"data row3 col0\" >MAE</td>\n",
       "      <td id=\"T_b5ea1_row3_col1\" class=\"data row3 col1\" >Peak Hours</td>\n",
       "      <td id=\"T_b5ea1_row3_col2\" class=\"data row3 col2\" >7.438055</td>\n",
       "      <td id=\"T_b5ea1_row3_col3\" class=\"data row3 col3\" >7.429516</td>\n",
       "      <td id=\"T_b5ea1_row3_col4\" class=\"data row3 col4\" >7.373625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b5ea1_row4_col0\" class=\"data row4 col0\" >RMSE</td>\n",
       "      <td id=\"T_b5ea1_row4_col1\" class=\"data row4 col1\" >Peak Hours</td>\n",
       "      <td id=\"T_b5ea1_row4_col2\" class=\"data row4 col2\" >9.273397</td>\n",
       "      <td id=\"T_b5ea1_row4_col3\" class=\"data row4 col3\" >9.257146</td>\n",
       "      <td id=\"T_b5ea1_row4_col4\" class=\"data row4 col4\" >9.181095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b5ea1_row5_col0\" class=\"data row5 col0\" >MAPE</td>\n",
       "      <td id=\"T_b5ea1_row5_col1\" class=\"data row5 col1\" >Peak Hours</td>\n",
       "      <td id=\"T_b5ea1_row5_col2\" class=\"data row5 col2\" >0.185381</td>\n",
       "      <td id=\"T_b5ea1_row5_col3\" class=\"data row5 col3\" >0.185512</td>\n",
       "      <td id=\"T_b5ea1_row5_col4\" class=\"data row5 col4\" >0.184392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x142392b60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create comparison table\n",
    "comparison_data = [\n",
    "    [\"MAE\", \"Overall\", metrics_baseline['mae_all'], metrics_r1['mae_all_best_r1'], metrics_r2['overall']['MAE']],\n",
    "    [\"RMSE\", \"Overall\", metrics_baseline['rmse_all'], metrics_r1['rmse_all_best_r1'], metrics_r2['overall']['RMSE']],\n",
    "    [\"MAPE\", \"Overall\", metrics_baseline['mape_all'], metrics_r1['mape_all_best_r1'], metrics_r2['overall']['MAPE']],\n",
    "    [\"MAE\", \"Peak Hours\", metrics_baseline['mae_peak'], metrics_r1['mae_peak_best_r1'], metrics_r2['peak_hours']['MAE']],\n",
    "    [\"RMSE\", \"Peak Hours\", metrics_baseline['rmse_peak'], metrics_r1['rmse_peak_best_r1'], metrics_r2['peak_hours']['RMSE']],\n",
    "    [\"MAPE\", \"Peak Hours\", metrics_baseline['mape_peak'], metrics_r1['mape_peak_best_r1'], metrics_r2['peak_hours']['MAPE']],\n",
    "]\n",
    "\n",
    "# Format into DataFrame\n",
    "comparison_df = pd.DataFrame(\n",
    "    comparison_data,\n",
    "    columns=[\"Metric\", \"Type\", \"Prophet Baseline\", \"Prophet R1\", \"Prophet R2\"]\n",
    ")\n",
    "\n",
    "# Display nicely\n",
    "comparison_df.style.set_caption(\"📊 Prophet Model Comparison (Baseline vs R1 vs R2)\")\\\n",
    "    .background_gradient(cmap=\"YlGnBu\", subset=[\"Prophet Baseline\", \"Prophet R1\", \"Prophet R2\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
